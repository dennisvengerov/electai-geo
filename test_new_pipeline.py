#!/usr/bin/env python3
"""
Test script for the complete new pipeline:
1. Gemini 2.0 Flash generates ranking queries
2. GPT-5 generates actual ranked responses
3. Gemini 2.5 Pro analyzes batches for citations and rankings
"""

import asyncio
import os
import json
from geo_analyzer import GEOAnalyzer


async def test_complete_pipeline():
    """Test the complete new pipeline end-to-end"""
    
    # Check for API keys
    openai_key = os.getenv("OPENAI_API_KEY")
    gemini_key = os.getenv("GEMINI_API_KEY")
    
    if not openai_key:
        print("❌ OPENAI_API_KEY environment variable not set")
        return
    
    if not gemini_key:
        print("❌ GEMINI_API_KEY environment variable not set")
        return
    
    print("🚀 Testing Complete New Pipeline...")
    print("📋 Pipeline Steps:")
    print("   1. Gemini 2.0 Flash → Generate ranking queries")
    print("   2. GPT-5 → Generate actual ranked responses")
    print("   3. Gemini 2.5 Pro → Batch analysis for citations/rankings")
    print()
    
    # Initialize analyzer with new pipeline
    analyzer = GEOAnalyzer(
        openai_api_key=openai_key,
        gemini_api_key=gemini_key,
        max_concurrent=2,
        use_batch_analysis=True
    )
    
    print(f"🔧 Pipeline Configuration:")
    print(f"   • Query Generation: Gemini 2.0 Flash")
    print(f"   • Ranking Generation: GPT-5")
    print(f"   • Batch Analysis: Gemini 2.5 Pro")
    print(f"   • Batch Analysis: {analyzer.use_batch_analysis}")
    print()
    
    def progress_callback(current, total, status):
        print(f"📊 Progress: {current}/{total} - {status}")
    
    try:
        # Run a small analysis to test the complete pipeline
        print("🧪 Running test analysis...")
        results = await analyzer.analyze_company_visibility(
            company_name="Burt's Bees",
            industry_context="lip balm and natural cosmetics",
            num_queries=3,  # Small number for testing
            progress_callback=progress_callback
        )
        
        print("\n✅ Pipeline Analysis Completed!")
        print(f"📈 Analysis method: {results.get('analysis_method', 'unknown')}")
        print(f"🎯 Total queries: {results.get('summary', {}).get('total_queries', 0)}")
        print(f"📊 Total citations: {results.get('summary', {}).get('total_citations', 0)}")
        print(f"💯 Analysis confidence: {results.get('summary', {}).get('analysis_confidence', 0):.2%}")
        
        # Examine individual query results
        query_results = results.get('query_results', [])
        print(f"\n📋 Query Results Analysis:")
        
        for i, result in enumerate(query_results, 1):
            cited = result.get('cited', False)
            position = result.get('position')
            mention_type = result.get('mention_type', 'none')
            ranking_type = result.get('ranking_type')
            has_ranking = result.get('has_numbered_ranking', False)
            
            print(f"\n  Query {i}: {result.get('query', '')[:60]}...")
            print(f"    ✓ Cited: {cited}")
            print(f"    📍 Position: {position}")
            print(f"    🎭 Mention Type: {mention_type}")
            print(f"    🏆 Has Ranking: {has_ranking}")
            if ranking_type:
                print(f"    📊 Ranking Type: {ranking_type}")
            
            # Show competitors found
            competitors = result.get('competitors', [])
            if competitors:
                print(f"    🏢 Competitors: {competitors[:3]}{'...' if len(competitors) > 3 else ''}")
            
            # Show competitor positions if available
            comp_positions = result.get('competitor_positions', {})
            if comp_positions:
                print(f"    🥇 Positions: {dict(list(comp_positions.items())[:3])}")
        
        # Check if we got ranking data
        has_any_rankings = any(r.get('has_numbered_ranking') for r in query_results)
        has_any_positions = any(r.get('position') for r in query_results)
        
        print(f"\n🔍 Pipeline Validation:")
        print(f"   • Queries generated by Gemini 2.0 Flash: ✅")
        print(f"   • Rankings generated by GPT-5: {'✅' if has_any_rankings else '❌'}")
        print(f"   • Positions extracted by Gemini 2.5 Pro: {'✅' if has_any_positions else '❌'}")
        print(f"   • Batch analysis completed: ✅")
        
        if has_any_rankings and has_any_positions:
            print("\n🎉 Complete pipeline test PASSED!")
            print("   All components working correctly:")
            print("   ✓ Query generation")
            print("   ✓ Ranking generation") 
            print("   ✓ Position extraction")
            print("   ✓ Batch analysis")
        else:
            print("\n⚠️ Pipeline partially working:")
            if not has_any_rankings:
                print("   ❌ GPT-5 may not be generating proper ranked lists")
            if not has_any_positions:
                print("   ❌ Gemini 2.5 Pro may not be extracting positions correctly")
            
        # Show timing information
        total_time = results.get('total_execution_time', 0)
        avg_time = total_time / len(query_results) if query_results else 0
        print(f"\n⏱️ Performance:")
        print(f"   • Total time: {total_time:.1f}s")
        print(f"   • Average per query: {avg_time:.1f}s")
        
        # Show a sample response to verify ranking generation
        if query_results:
            sample_result = query_results[0]
            sample_response = sample_result.get('response', '')
            if sample_response and len(sample_response) > 100:
                print(f"\n📝 Sample GPT-5 Response Preview:")
                print(f"   {sample_response[:200]}...")
                
                # Check if it contains numbered lists
                has_numbers = any(f"{i}." in sample_response for i in range(1, 11))
                print(f"   Contains numbered lists: {'✅' if has_numbers else '❌'}")
        
    except Exception as e:
        print(f"\n❌ Pipeline test failed: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test_complete_pipeline())
